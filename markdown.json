{"version":1,"dicts":{"\\en\\index.md":"# Placeholder of HomePage","\\zh\\getting_started.md":"# Muta 入门\r\n\r\n- [Muta 入门](#muta-%e5%85%a5%e9%97%a8)\r\n  - [安装和运行](#%e5%ae%89%e8%a3%85%e5%92%8c%e8%bf%90%e8%a1%8c)\r\n    - [安装依赖](#%e5%ae%89%e8%a3%85%e4%be%9d%e8%b5%96)\r\n      - [MacOS](#macos)\r\n      - [ubuntu](#ubuntu)\r\n      - [centos7](#centos7)\r\n      - [archlinux](#archlinux)\r\n    - [直接下载预编译的二进制文件](#%e7%9b%b4%e6%8e%a5%e4%b8%8b%e8%bd%bd%e9%a2%84%e7%bc%96%e8%af%91%e7%9a%84%e4%ba%8c%e8%bf%9b%e5%88%b6%e6%96%87%e4%bb%b6)\r\n    - [从源码编译](#%e4%bb%8e%e6%ba%90%e7%a0%81%e7%bc%96%e8%af%91)\r\n      - [获取源码](#%e8%8e%b7%e5%8f%96%e6%ba%90%e7%a0%81)\r\n      - [安装 rust](#%e5%ae%89%e8%a3%85-rust)\r\n      - [编译](#%e7%bc%96%e8%af%91)\r\n    - [运行单节点](#%e8%bf%90%e8%a1%8c%e5%8d%95%e8%8a%82%e7%82%b9)\r\n    - [运行多节点](#%e8%bf%90%e8%a1%8c%e5%a4%9a%e8%8a%82%e7%82%b9)\r\n  - [使用 docker](#%e4%bd%bf%e7%94%a8-docker)\r\n  - [配置说明](#%e9%85%8d%e7%bd%ae%e8%af%b4%e6%98%8e)\r\n\r\n## 安装和运行\r\n\r\n此处讲解在你的操作系统直接安装 muta 的方法，如果想要通过 docker 快速尝试 muta，可以参考 [使用 docker](#%e4%bd%bf%e7%94%a8-docker)。\r\n\r\n### 安装依赖\r\n\r\n#### MacOS\r\n\r\n```\r\nbrew install autoconf libtool\r\n```\r\n\r\n#### ubuntu\r\n\r\n```\r\napt update\r\napt install -y git curl openssl cmake pkg-config libssl-dev gcc build-essential clang libclang-dev\r\n```\r\n\r\n#### centos7\r\n\r\n```\r\nyum install -y centos-release-scl\r\nyum install -y git make gcc-c++ openssl-devel llvm-toolset-7\r\n\r\n# 打开 llvm 支持\r\nscl enable llvm-toolset-7 bash\r\n```\r\n\r\n#### archlinux\r\n\r\n```\r\npacman -Sy --noconfirm git gcc pkgconf clang make\r\n```\r\n\r\n### 直接下载预编译的二进制文件\r\n \r\n我们会通过 [github releases](https://github.com/nervosnetwork/muta/releases) 发布一些常用操作系统的预编译二进制文件。如果其中包含你的操作系统，可以直接下载对应的文件。\r\n \r\n### 从源码编译\r\n\r\n#### 获取源码\r\n\r\n通过 git 下载源码：\r\n\r\n```\r\ngit clone https://github.com/nervosnetwork/muta.git\r\n```\r\n\r\n或者在 [github releases](https://github.com/nervosnetwork/muta/releases) 下载源码压缩包解压。\r\n\r\n#### 安装 rust\r\n\r\n参考： <https://www.rust-lang.org/tools/install>\r\n\r\n```\r\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\r\n```\r\n\r\n#### 编译\r\n\r\n```\r\ncd /path/to/muta\r\nmake prod\r\n```\r\n\r\n编译完成后的二进制文件在 `target/release/muta-chain`。\r\n\r\n### 运行单节点\r\n\r\n```\r\ncd /path/to/muta\r\n\r\n# 使用默认配置运行 muta\r\n# 如果是直接下载的 binary，请自行替换下面的命令为对应的路径\r\n./target/release/muta-chain\r\n\r\n# 查看帮助\r\n$ ./target/release/muta-chain  -h\r\nMuta v0.1.0\r\nMuta Dev <muta@nervos.org>\r\n\r\nUSAGE:\r\n    muta-chain [OPTIONS]\r\n\r\nFLAGS:\r\n    -h, --help       Prints help information\r\n    -V, --version    Prints version information\r\n\r\nOPTIONS:\r\n    -c, --config <FILE>     a required file for the configuration [default: ./devtools/chain/config.toml]\r\n    -g, --genesis <FILE>    a required file for the genesis json [default: ./devtools/chain/genesis.json]\r\n```\r\n\r\n### 运行多节点\r\n\r\n1. 根据节点拓扑，修改配置文件 config.toml，主要注意其中的 privkey、network 和 verifier_list 部分，可以参考下面的 docker-compose 配置，或者详细阅读下文的配置说明；\r\n2. 将 muta binary 文件、muta 配置 config.toml 和创世块文件 genesis.json 分发到待部署的节点机器；\r\n3. 启动 bootstrap 节点；\r\n4. 启动其它节点；\r\n\r\n## 使用 docker\r\n\r\n```\r\ndocker run -it --init -p 8000:8000 nervos/muta\r\n\r\n# 如果想要保留链的数据，可以数据目录挂载到 host 机器\r\ndocker run -it --init -p 8000:8000 -v `pwd`/data:/app/devtools/chain/data nervos/muta\r\n```\r\n \r\n可以访问 <http://localhost:8000/graphiql> 页面与链进行交互。\r\n\r\n \r\n使用 docker compose 运行多节点：\r\n\r\n```\r\ndocker-compose -f devtools/docker/dockercompose/docker-compose-bft.yaml up\r\n```\r\n\r\n此处默认启动 4 节点，数据在 `target/data/bft1` ~ `target/data/bft4` 文件夹下, 可以查看 `docker-compose-bft.yaml` 获取更详细的配置信息。\r\n \r\n## 配置说明\r\n\r\n默认的配置样例在 `./devtools/chain/config.toml`，此处对其中的一些字段进行说明。\r\n\r\n```toml\r\n# chain id，链的唯一标识，同一个链的所有节点该项配置必须相同\r\nchain_id = \"b6a4d7da21443f5e816e8700eea87610e6d769657d6b8ec73028457bf2ca4036\"  # by sha256(Muta)\r\n\r\n# 节点私钥，节点的唯一标识，在作为 bootstraps 节点时，需要给出地址和该私钥对应的公钥让其他节点连接；如果是出块节点，该私钥对应的地址需要在 consensus verifier_list 中\r\nprivkey = \"45c56be699dca666191ad3446897e0f480da234da896270202514a0e1a587c3f\"\r\n\r\n# db config，链数据所在目录\r\ndata_path = \"./devtools/chain/data\"\r\n\r\n[graphql]\r\n# graphql 监听地址\r\nlistening_address = \"0.0.0.0:8000\"\r\n# graphql 访问路径\r\ngraphql_uri = \"/graphql\"\r\n# graphiql 路径\r\ngraphiql_uri = \"/graphiql\"\r\n\r\n[network]\r\n# p2p 监听地址\r\nlistening_address = \"0.0.0.0:1337\"\r\n\r\n[[network.bootstraps]]\r\n# 初始启动时访问的节点信息\r\npubkey = \"031288a6788678c25952eba8693b2f278f66e2187004b64ac09416d07f83f96d5b\"\r\naddress = \"0.0.0.0:1888\"\r\n\r\n# 交易池相关配置\r\n[mempool]\r\n# 最大超时间隔，如果 当前区块数 + timeout_gap > tx 中的 timeout 字段，则交易池会拒绝接收该交易\r\ntimeout_gap = 20\r\n# 交易池大小\r\npool_size = 20000\r\n# 为了增加性能，每积累到这么多个交易才对外广播一次\r\nbroadcast_txs_size = 200\r\n# 交易池广播交易间隔，单位为 毫秒(ms)\r\nbroadcast_txs_interval = 200\r\n\r\n[consensus]\r\n# 最大 cycles 限制\r\ncycles_limit = 99999999\r\n# cycle 价格\r\ncycles_price = 1\r\n# 出块间隔，单位为 毫秒(ms)\r\ninterval = 3000\r\n# 出块节点的地址合集\r\nverifier_list = [ \"10f8389d774afdad8755ef8e629e5a154fddc6325a\" ]\r\n\r\n# 共识相关配置\r\n[consensus.duration]\r\n# 下面两项标识 propose 阶段的超时时间占共识间隔的比例的分子和分母。\r\n# 按照上述配置为 3000ms，则 propose 共识阶段的超时时间为 3000ms * 24 / 30 = 2400ms。\r\n# 下面类似的有 prevote 和 precommit 阶段的超时设置。\r\npropose_numerator = 24\r\npropose_denominator = 30\r\nprevote_numerator = 6\r\nprevote_denominator = 30\r\nprecommit_numerator = 6\r\nprecommit_denominator = 30\r\n\r\n[executor]\r\n# 设为 true 时，节点将只保存最新高度的 state\r\nlight = false\r\n```","\\zh\\index.md":"# Muta 文档\r\n\r\n- [概览](./overview.md)\r\n- [快速开始](./getting_started.md)\r\n- 模块设计\r\n  - [交易池](./transaction_pool.md)\r\n  - [Overlord 共识](./overlord.md)\r\n  - [合约语言](./vm_lang.md)\r\n  - [网络](./network.md)\r\n- 合约开发\r\n  - [在 CKB-VM 上运行 TypeScript](./toolchain_minits_on_ckbvm.md)","\\zh\\network.md":"## 网络设计\r\n\r\n- [网络设计](#%e7%bd%91%e7%bb%9c%e8%ae%be%e8%ae%a1)\r\n  - [当前目标](#%e5%bd%93%e5%89%8d%e7%9b%ae%e6%a0%87)\r\n  - [消息收发](#%e6%b6%88%e6%81%af%e6%94%b6%e5%8f%91)\r\n    - [节点消息端 (Endpoint)](#%e8%8a%82%e7%82%b9%e6%b6%88%e6%81%af%e7%ab%af-endpoint)\r\n      - [Gossip](#gossip)\r\n      - [RPC Call](#rpc-call)\r\n      - [RPC Response](#rpc-response)\r\n    - [消息序列化](#%e6%b6%88%e6%81%af%e5%ba%8f%e5%88%97%e5%8c%96)\r\n    - [消息处理](#%e6%b6%88%e6%81%af%e5%a4%84%e7%90%86)\r\n    - [消息处理逻辑注册](#%e6%b6%88%e6%81%af%e5%a4%84%e7%90%86%e9%80%bb%e8%be%91%e6%b3%a8%e5%86%8c)\r\n    - [消息的发送](#%e6%b6%88%e6%81%af%e7%9a%84%e5%8f%91%e9%80%81)\r\n\r\n### 当前目标\r\n\r\n基于 [tentacle crate](https://github.com/nervosnetwork/p2p) 实现一个简单的可工作的 P2P 网络，主要功能如下：\r\n\r\n- 节点身份\r\n\r\n  - PeerID: secp256k1 的公钥派生出的 ID，[tentacle-secio](https://crates.io/crates/tentacle-secio)\r\n  - Address: MultiAddress [REF](https://multiformats.io/multiaddr)，只支持 TCP\r\n\r\n- 节点发现\r\n\r\n  - bootstrap，[tentacle-discovery](https://crates.io/crates/tentacle-discovery)\r\n\r\n- 节点质量维护\r\n\r\n  - ping，[tentacle-ping](https://crates.io/crates/tentacle-ping)，超时断开\r\n\r\n- 节点持久化\r\n\r\n  - 基于文件的简易持久化，服务退出时，将保存节点信息，默认关闭\r\n\r\n- 消息广播以及单播\r\n\r\n  - 基础的广播服务，以及基于 secp256k1 公钥地址的单播\r\n\r\n- 消息加密传输\r\n\r\n  - 基于 [tentacle-secio](https://crates.io/crates/tentacle-secio)\r\n\r\n- 其他\r\n\r\n  - 消息优先级: 使用 tentacle 自带的消息发送优先级，目前只有两种，High 和 Normal\r\n  - 消息压缩: 使用 snappy\r\n  - 消息处理: 基于 handler 注册形式，由各个模块自定义接受消息处理逻辑\r\n\r\n### 消息收发\r\n\r\n#### 节点消息端 (Endpoint)\r\n\r\n节点通过注册消息端地址对外暴露服务，实现消息接受及处理。目前提供三种类型的地址：\r\n\r\n##### Gossip\r\n\r\n```text\r\n/gossip/[service_name]/[message_name]\r\n```\r\n\r\n消息单向广播以及单播\r\n\r\n##### RPC Call\r\n\r\n```text\r\n/rpc_call/[service_name]/[message_name]\r\n```\r\n\r\n##### RPC Response\r\n\r\n```text\r\n/rpc_resp/[service_name]/[message_name]\r\n```\r\n\r\nRPC 用于节点之间的消息交互通信，RPC Call 发送请求，RPC Response 返回。\r\n\r\n#### 消息序列化\r\n\r\n序列化采用 protobuf ，消息需要实现 MessageCodec trait 。\r\n\r\n```rust\r\n#[async_trait]\r\npub trait MessageCodec: Sized + Send + Debug + 'static {\r\n    async fn encode(&mut self) -> ProtocolResult<Bytes>;\r\n\r\n    async fn decode(bytes: Bytes) -> ProtocolResult<Self>;\r\n}\r\n```\r\n\r\n目前针对实现了 serde Serialize 和 Deserialize trait 的消息自动实现了 MessageCodec ，\r\n采用 bincode 作为中间序列化过渡。\r\n\r\n#### 消息处理\r\n\r\n消息处理需要实现 MessageHandler trait\r\n\r\n```rust\r\n#[async_trait]\r\npub trait MessageHandler: Sync + Send + 'static {\r\n    type Message: MessageCodec;\r\n\r\n    async fn process(&self, ctx: Context, msg: Self::Message) -> ProtocolResult<()>;\r\n}\r\n```\r\n\r\n#### 消息处理逻辑注册\r\n\r\n完成上述实现之后，可通过如下接口，完成消息逻辑处理的注册。\r\n\r\n```rust\r\npub fn register_endpoint_handler<M>(\r\n    &mut self,\r\n    end: &str,\r\n    handler: Box<dyn MessageHandler<Message = M>>,\r\n) -> ProtocolResult<()>\r\nwhere\r\n    M: MessageCodec;\r\n\r\npub fn register_rpc_response<M>(&mut self, end: &str) -> ProtocolResult<()>\r\nwhere\r\n    M: MessageCodec;\r\n```\r\n\r\n`Gossip` 和 `RPC Call` 都需要通过 `register_endpoint_handler` 完成注册，\r\n而 `RPC Response` 需要通过 `register_rpc_response` 完成注册。\r\n\r\n未来计划将 `RPC Response` 注册去掉。\r\n\r\n`end` 即签名提到的节点消息端 `Endpoint` 缩写。\r\n\r\n#### 消息的发送\r\n\r\n```rust\r\n#[async_trait]\r\npub trait Gossip: Send + Sync {\r\n    async fn broadcast<M>(&self, cx: Context, end: &str, msg: M, p: Priority) -> ProtocolResult<()>\r\n    where\r\n        M: MessageCodec;\r\n\r\n    async fn users_cast<M>(\r\n        &self,\r\n        cx: Context,\r\n        end: &str,\r\n        users: Vec<UserAddress>,\r\n        msg: M,\r\n        p: Priority,\r\n    ) -> ProtocolResult<()>\r\n    where\r\n        M: MessageCodec;\r\n}\r\n\r\n#[async_trait]\r\npub trait Rpc: Send + Sync {\r\n    async fn call<M, R>(&self, ctx: Context, end: &str, msg: M, pri: Priority) -> ProtocolResult<R>\r\n    where\r\n        M: MessageCodec,\r\n        R: MessageCodec;\r\n\r\n    async fn response<M>(&self, cx: Context, end: &str, msg: M, p: Priority) -> ProtocolResult<()>\r\n    where\r\n        M: MessageCodec;\r\n}\r\n```\r\n\r\n如上述定义，网路服务实例化后，可通过调用 `handle()` 获取一个网络服务引用，该\r\n`handle` 实现了上述的接口，同时实现了 `Clone`。各模块可以通过它来完成消息的\r\n发送。\r\n\r\n注意：`UserAddress` 目前同 `tentacle-secio` 提供的 secp256k1 公钥绑定。\r\n","\\zh\\overlord.md":"# Overlord 架构设计\r\n\r\n- [目标](#目标)\r\n- [设计背景](#设计背景)\r\n- [Overlord 协议](#Overlord协议)\r\n  - [总体设计](#总体设计)\r\n  - [协议描述](#协议描述)\r\n- [Overlord 架构](#Overlord架构)\r\n  - [共识状态机](#共识状态机)\r\n  - [状态存储](#状态存储)\r\n  - [定时器](#定时器)\r\n  - [Wal](#Wal)\r\n- [Overlord 接口](#Overlord接口)\r\n  - [共识接口](#共识接口)\r\n  - [密码学接口](#密码学接口)\r\n\r\n## 目标\r\n\r\nOverlord 的目标是成为能够支持上百个共识节点，满足数千笔每秒的交易处理能力，且交易延迟不超过数秒的 BFT 共识算法。简单来讲，就是能够满足大部分现实业务需求的高性能共识算法。\r\n\r\n## 设计背景\r\n\r\n在区块链中，一次共识至少包含两层语义：\r\n\r\n1. 完成交易定序\r\n2. 对最新状态达成共识\r\n\r\n对于 UTXO 模型的区块链来说，新状态隐含在交易输出中，因此 1 和 2 是一体不可分割的。而对于 Account 模型的区块链来说，交易中并没有包含状态，只有执行完交易才能生成最新状态，状态用单独的一颗 MPT 树保存。\r\n\r\n在 Account 模型中，为了实现第二层语义，常用的办法是，共识节点在打包新区块之前执行完区块中的所有交易，以计算出最新状态保存到块头中。包含了最新状态的区块达成共识后，区块中的交易完成了定序，同时最新状态亦完成了共识，任何节点可以重放区块中的交易验证状态的正确性。然而，这种处理方法制约了 BFT 类共识算法的交易处理能力。如下图所示，当高度为 h 的区块 B(h) 达成共识后，高度为 h+1 的新 leader 打包并执行 B(h+1) 后才能广播 B(h+1)，其他共识节点收到 B(h+1) 后必须再执行 B(h+1) 以验证其正确性。在共识过程中，这两次串行的区块执行过程拖慢了共识效率。\r\n\r\n<div align=center><img src=\"./resources/block_process.png\"></div>\r\n\r\n一种改进的办法是，Leader 在打包新区块时并不立即执行该块，待区块达成共识后，共识节点才执行该块生成新的状态，下一个高度的 Leader 将新状态与下一个区块一起参与共识。这种办法省掉了一次区块执行过程。\r\n\r\n当从更微观的角度来审察这种改进方案时，我们发现其仍然存在很大的改进空间。这是因为，任何一个共识节点的共识模块和执行模块在整个共识过程中始终是串行的，如上图所示，当共识模块在对区块共识时，执行模块始终是空闲的，反之亦然。如果能够将执行模块和共识模块并行，那么共识的交易处理能力理论上能够达到执行模块的最大处理极限。\r\n\r\n## Overlord 协议\r\n\r\n### 总体设计\r\n\r\nOverlord 的核心思想是解耦交易定序与状态共识。\r\n\r\n我们用 B(h, S, T) 表示高度为 h 的区块，其包含的状态是 S，定序的交易集合是 T。在共识的第二层语义中，人们对 S 的解读往往是执行完 T 后的状态，正是这种思维定势使得执行模块和共识模块无法并行。如果将 S 理解为是共识模块在开始对 B(h, S, T) 共识时，执行模块执行达到的最新状态，那么共识模块将无需等待执行模块执行新的区块，而执行模块只需要沿着已定序的交易向前执行。这样，共识模块可以连续向前推进，不断将新交易定序，同时完成执行模块的最新状态共识; 执行模块也可以连续执行已定序的交易集合，直到将所有已定序的交易执行完毕。\r\n\r\n### 协议描述\r\n\r\n在 Overlord 中，一次共识过程称为一个 *epoch*，我们将达成共识的区块称为 *epoch*。*epoch* 包含 Header 和 Body 两部分（如下图所示）。*epoch* 的核心结构如下图所示，`epoch_id` 是单调递增的数值，相当于高度；`prev_hash` 是上一个 *epoch* 的哈希；`order_root` 是包含在 Body 中的所有待定序的交易的 merkle root；`state_root` 表示最新的世界状态的 MPT Root；`confirm_roots` 表示从上一个 *epoch* 的 `state_root` 到当前 *epoch* 的 `state_root` 之间执行模块向前推进的 `order_root` 集合；`receipt_roots` 记录被执行的每一个 `order_root` 所对应的 `receipt_root`；`proof` 是对上一个 *epoch* 的证明。\r\n\r\n<div align=center><img src=\"./resources/epoch.png\"></div>\r\n\r\n在具体的方案中，共识模块批量打包交易进行共识, 达成共识后, 将已定序的交易集合添加到待执行的队列中, 执行模块以交易集合为单位依次执行, 每执行完一个交易集合, 就将被执行的交易集合的 order_root, 以及执行后的 stateRoot 发给共识模块。在 Leader 打包交易拼装 *epoch* 时, 取最新收到的 state_root 作为最新状态参与共识.\r\n\r\nOverlord 是在具体共识算法之上的解释层, 通过重新诠释共识的语义, 使得交易定序与状态共识解耦, 从而在实际运行中获得更高的交易处理能力。理论上, Overlord 能够基于几乎任何 BFT 类共识算法, 具体在我们的项目中则是基于改进的 Tendermint。\r\n\r\n我们对 Tendermint 主要做了三点改进：\r\n\r\n1. 将聚合签名应用到 Tendermint 中, 使共识的消息复杂度从 <img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;O(n^{2})\" title=\"O(n^{2})\" /> 降到 <img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;O(n)\" title=\"O(n)\" />, 从而能够支持更多的共识节点\r\n2. 在 *proposal* 中增加了 propose 交易区, 使新交易的同步与共识过程可并行\r\n3. 共识节点收到 *proposal* 后, 无需等 *epoch* 校验通过即可投 *prevote* 票, 而在投 *precommit* 票之前必须得到 *epoch* 校验结果, 从而使得区块校验与 *prevote* 投票过程并行\r\n\r\n#### 聚合签名\r\n\r\n在 Tendermint 共识协议中，节点在收到 *proposal* 之后对其投出 *prevote*，*prevote* 投票是全网广播给其他节点的。这时的通信复杂度是 <img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;O(n^{2})\" title=\"O(n^{2})\" />。使用聚合签名优化是所有的节点将 *prevote* 投票发给一个指定的 *Relayer* 节点，Relayer 节点可以是任何一个共识节点。Relayer 节点将收到的签名通过算法计算聚合签名，再用一个位图 (bit-vec) 表示是哪些节点的投票。将聚合签名和位图发送给其他节点，对于 *precommit* 投票同理。这样就将通信复杂度降到了 <img src=\"https://latex.codecogs.com/svg.latex?\\inline&space;O(n)\" title=\"O(n)\" />。\r\n\r\n如果 *Relayer* 出现故障，没有发送聚合签名给共识节点，或者 *Relayer* 作恶，只给小部分共识节点发送聚合签名，那么共识将会失活。我们采用超时投空票的方式解决这个问题。当节点在投出 *prevote* 投票之后，立即设置一个定时器，如果的超时时间内没有收到 *prevoteQC* 直接进入预提交状态，投出 *nil precommit* 投票。之后进入到下一个 round。如果预投票阶段正常，投出 *precommit* 之后同样设置一个定时器，如果超时没有收到 *precommitQC* 则直接进入下一个 round。\r\n\r\n#### 同步并行\r\n\r\nOverlord 采用压缩区块（compact block）的方式广播 *CompactEpoch*，即其 Body 中仅包含交易哈希，而非完整交易。共识节点收到 *CompactEpoch* 后，需要同步获得其 Body 中包含的全部完整交易后才能构造出完整的 *epoch*。\r\n\r\n我们在 proposal 里除了包含 *CompactEpoch* 外，还额外增加了一个 *propose* *交易区，propose* 交易区中包含待同步的新交易的哈希。需要注意的是，这些交易与 *CompactEpoch* 里包含的待定序的交易哈希并不重叠，当 *CompactEpoch* 不足以包含交易池中所有的新交易时，剩余的新交易可以包含到 *propose* 交易区中提前同步。这在系统交易量很大的时候，可以提高交易同步与共识的并发程度，进一步提高交易处理能力.\r\n\r\n#### 校验并行\r\n\r\n共识节点收到 *proposal* 后，将 *CompactEpoch* 的校验(获得完整交易，校验交易的正确性) 与 *prevote* 投票并行，只有当收到 *prevote* 聚合签名和 *CompactEpoch* 的检验结果后，才会投 *precommit* 票。\r\n\r\n## Overlord 架构\r\n\r\nOverlord 共识由以下几个组件组成的：\r\n\r\n* 状态机(SMR)：根据输入消息的进行状态转换\r\n\r\n* 状态存储(State)：用于存储提议，投票等状态\r\n\r\n* 定时器(Timer)：设定超时时间触发状态机操作\r\n\r\n* Wal：用于读写 Wal 日志\r\n\r\n在 Overlord 共识架构中，当收到消息时，状态存储模块先对消息做基本检查。通过后，根据接收到的消息更新状态，并将消息传输给状态机。此外，为了保持活性还需要一个定时器，当超时时定时器调用接口触发状态机。状态机在做状态变更之后会抛出一个当前状态的事件，状态存储模块和定时器模块监听状态机抛出的事件，根据监听到的事件做相应的处理，例如写 Wal，发送投票，设置定时器等。在重启时状态存储模块先从 Wal 中读取数据，再发送给状态机。整体的架构如下图所示：\r\n\r\n<div align=center><img src=\"./resources/arch_overlord.png\"></div>\r\n\r\n### 共识状态机(SMR)\r\n\r\n状态机模块是整个共识的逻辑核心，它主要的功能是状态变更和 **lock** 的控制。当收到消息触发时，根据收到的消息做状态变更，并将变更后的状态作为事件抛出。在我们的实现中，Overlord 使用一个应用 BLS 聚合签名优化的 Tendermint 状态机进行共识，整体的工作过程如下.\r\n\r\n#### 提议阶段\r\n\r\n节点使用确定性随机算法确定本轮的 *Leader*。\r\n\r\n**Leader**: 广播一个 *proposal*\r\n\r\n**Others**: 设置一个定时器 T1，当收到 *proposal* 之后向 *Relayer* 发送 *prevote* 投票\r\n\r\n#### 预投票阶段\r\n\r\n**Relayer**: 设置一个定时器 T2，对收到的 *prevote* 投票进行聚合并生成位图，将聚合后的投票和位图广播给其他节点\r\n\r\n**Others**: 设置一个定时器 T2，检查聚合的 *prevote* 投票的合法性，生成 **PoLC** 发送 *precommit* 投票\r\n\r\n#### 校验等待阶段\r\n\r\n所有节点设置一个定时器 T3，当收到对 *proposal* 的校验结果之后，进入预提交阶段\r\n\r\n#### 预提交阶段\r\n\r\n**Relayer**: 设置一个定时器 T4，对收到的 *precommit* 投票进行聚合并生成位图，将聚合后的投票和位图广播给其他节点\r\n\r\n**Others**: 设置一个定时器 T4，检查聚合的 *precommit* 投票的合法性\r\n\r\n#### 提交阶段\r\n\r\n所有节点将 *proposal* 提交\r\n\r\n共识状态机的状态转换图如下图所示：\r\n\r\n<div align=center><img src=\"./resources/state_transition.png\"></div>\r\n\r\n在工程中，我们将预投票阶段和校验等待阶段合并为一个阶段，共用一个超时时间。当状态机收到聚合后的投票和校验结果之后，进入到预提交阶段。\r\n\r\n#### 状态机状态\r\n\r\n状态机模块需要存储的状态有：\r\n\r\n* *epoch_id*: 当前共识的 epoch\r\n\r\n* *round*: 当前共识的轮次\r\n\r\n* *step*: 当前所在的阶段\r\n\r\n* *proposal_hash*: 可选，当前正在共识的哈希\r\n\r\n* *lock*: 可选，当前是否已经达成 **PoLC**\r\n\r\n#### 数据结构\r\n\r\n状态机的触发结构如下：\r\n\r\n```rust\r\npub struct SMRTrigger {\r\n    pub hash: Hash,\r\n    pub round: Option<u64>,\r\n    pub trigger_type: TriggerType,\r\n}\r\n```\r\n\r\n状态机的输出结构如下：\r\n\r\n```rust\r\npub enum SMREvent {\r\n    /// New round event\r\n    /// for state: update round,\r\n    /// for timer: set a propose step timer.\r\n    NewRoundInfo {\r\n        round: u64,\r\n        lock_round: Option<u64>,\r\n        lock_proposal: Option<Hash>,\r\n    },\r\n    /// Prevote event,\r\n    /// for state: transmit a prevote vote,\r\n    /// for timer: set a prevote step timer.\r\n    PrevoteVote(Hash),\r\n    /// Precommit event,\r\n    /// for state: transmit a precommit vote,\r\n    /// for timer: set a precommit step timer.\r\n    PrecommitVote(Hash),\r\n    /// Commit event\r\n    /// for state: do commit,\r\n    /// for timer: do nothing.\r\n    Commit(Hash),\r\n}\r\n```\r\n\r\n#### 状态机接口\r\n\r\n```rust\r\n/// Create a new SMR service.\r\npub fn new() -> Self\r\n/// Trigger a SMR action.\r\npub fn trigger(&self, gate: SMRTrigger) -> Result<(), Error>\r\n/// Goto a new consensus epoch.\r\npub fn new_epoch(&self, epoch_id: u64) -> Result<(), Error>\r\n```\r\n\r\n### 状态存储(State)\r\n\r\n状态存储模块是整个共识的功能核心，主要的功能为存储状态，消息分发，出块和密码学相关操作。在工作过程中，对于网络层传输来的消息，首先进行验签，校验消息的合法性。对通过的消息判断是否需要写入 Wal。之后将消息发送给状态机。状态存储模块时刻监听状态机抛出的事件，并根据事件作出相应的处理。\r\n\r\n#### 存储状态\r\n\r\n状态存储模块需要存储的状态有：\r\n\r\n* *epoch_id*: 当前共识的 epoch\r\n\r\n* *round*: 当前共识的轮次\r\n\r\n* *proposals*: 缓存当前 epoch 所有的提议\r\n\r\n* *votes*: 缓存当前 epoch 所有的投票\r\n\r\n* *QCs*: 缓存当前 epoch 所有的 *QC*\r\n\r\n* *authority_manage*: 共识列表管理\r\n\r\n* *is_leader*: 节点是不是 *leader*\r\n  \r\n* *proof*: 可选，上一个 epoch 的证明\r\n\r\n* *last_commit_round*: 可选，上一次提交的轮次\r\n\r\n* *last_commit_proposal*: 可选，上一次提交的提议\r\n\r\n#### 消息分发\r\n\r\n发送消息时，根据消息及参数选择发送消息的方式（广播给其他节点或发送给 *Relayer*）。\r\n\r\n#### 出块\r\n\r\n当状态存储模块监听到状态机抛出的 `NewRound` 事件时，通过一个确定性随机数算法判断自己是不是出块节点。如果是出块节点则提出一个 proposal。\r\n\r\n*确定性随机数算法*：因为 Overlord 共识协议允许设置不同的出块权重和投票权重，在判断出块时，节点将出块权重进行归一化，并投射到整个 `u64` 的范围中，使用当前 `epoch_id` 与 `round` 之和作为随机数种子，判断生成的随机数落入到`u64` 范围中的哪一个区间中，该权重对应的节点即为出块节点。\r\n\r\n#### 密码学操作\r\n\r\n密码学操作包括如下方法：\r\n\r\n* 收到消息时，对消息进行验签\r\n\r\n* 收到聚合投票时，验签并校验权重是否超过阈值\r\n\r\n* 发出提议或投票时，对消息进行签名\r\n\r\n* 自己是 *Relayer* 时，对收到的投票进行聚合\r\n\r\n#### 状态存储接口\r\n\r\n### 定时器\r\n\r\n当状态机运行到某些状态的时候，需要设定定时器以便超时重发等操作。定时器模块会监听状态机抛出的事件，根据事件设置定时器。当达到超时时间，调用状态机模块的接口触发超时。定时器与状态存储复用 `SMREvent` 和接口。\r\n\r\n### Wal\r\n\r\n在共识过程中，需要将一些消息写入到 Wal 中。当重启时，状态存储模块首先从 Wal 中读取消息，回复重启前的状态。Wal 模块只与状态存储模块交互。\r\n\r\n#### Wal 接口\r\n\r\n```rust\r\n/// Create a new Wal struct.\r\npub fn new(path: &str) -> Self\r\n/// Set a new epoch of Wal, while go to new epoch.\r\npub fn set_epoch(&self, epoch_id: u64) -> Result<(), Error>\r\n/// Save message to Wal.\r\npub async fn save(&self, msg_type: WalMsgType, msg: Vec<u8>) -> Result<(), Error>;\r\n/// Load message from Wal.\r\npub fn load(&self) -> Vec<(WalMsgType, Vec<u8>)>\r\n```\r\n\r\n## Overlord 接口\r\n\r\n### 共识接口\r\n\r\n```rust\r\n#[async_trait]\r\npub trait Consensus<T: Serialize + Deserialize + Clone + Debug> {\r\n    /// Consensus error\r\n    type Error: ::std::error::Error;\r\n    /// Get an epoch of an epoch_id and return the epoch with its hash.\r\n    async fn get_epoch(\r\n        &self,\r\n        ctx: Context,\r\n        epoch_id: u64\r\n    ) -> Result<(T, Hash)), Self::Error>;\r\n    /// Check the correctness of an epoch.\r\n    async fn check_epoch(\r\n        &self,\r\n        ctx: Context,\r\n        hash: Hash\r\n    ) -> Result<(), Self::Error>;\r\n    /// Commit an epoch.\r\n    async fn commit(\r\n        &self, ctx: Context,\r\n        epoch_id: u64,\r\n        commit: Commit<T>\r\n    ) -> Result<Status, Self::Error>;\r\n    /// Transmit a message to the Relayer.\r\n    async fn transmit_to_relayer(\r\n        &self,\r\n        ctx: Context,\r\n        msg: OutputMsg,\r\n        addr: Address\r\n    ) -> Result<(), Self::Error>;\r\n    /// Broadcast a message to other replicas.\r\n    async fn broadcast_to_other(\r\n        &self,\r\n        ctx: Context,\r\n        msg: OutputMsg\r\n    ) -> Result<(), Self::Error>;\r\n}\r\n```\r\n\r\n### 密码学接口\r\n\r\n```rust\r\npub trait Crypto {\r\n    /// Crypto error.\r\n    type Error: ::std::error::Error;\r\n    /// Hash a message.\r\n    fn hash(&self, msg: &[u8]) -> Hash;\r\n    /// Sign to the given hash by private key.\r\n    fn sign(&self, hash: Hash) -> Result<Signature, Self::Error>;\r\n    /// Aggregate signatures into an aggregated signature.\r\n    fn aggregate_signatures(&self, signatures: Vec<Signatures>) -> Result<Signature, Self::Error>;\r\n    /// Verify a signature.\r\n    fn verify_signature(&self, signature: Signature, hash: Hash) -> Result<Address, Self::Error>;\r\n    /// Verify an aggregated signature.\r\n    fn verify_aggregated_signature(&self, aggregate_signature: Signature) -> Result<(), Self::Error>;\r\n}\r\n```\r\n","\\zh\\overlord_data_structure.md":"# Overlord 数据结构\r\n\r\n## 类型\r\n\r\n```rust\r\ntype Address = Vec<u8>;\r\n\r\ntype Signature = Vec<u8>;\r\n\r\ntype Hash = Vec<u8>;\r\n```\r\n\r\n## 枚举\r\n\r\n```rust\r\npub enum Role {\r\n    Leader = 0,\r\n    Replica = 1,\r\n}\r\n\r\npub enum VoteType {\r\n    Prevote = 0,\r\n    Precommit = 1,\r\n}\r\n\r\npub enum OutputMsg {\r\n    SignedProposal(SignedProposal),\r\n    SignedVote(SignedVote),\r\n    AggregatedVote(AggregatedVote),\r\n}\r\n```\r\n\r\n## Proposal\r\n\r\n```rust\r\npub struct SignedProposal<T> {\r\n    pub signature: Signature,\r\n    pub proposal: Proposal<T>,\r\n}\r\n\r\npub struct Proposal<T> {\r\n    pub epoch: u64,\r\n    pub round: u64,\r\n    pub content: T,\r\n    pub lock_round: Option<u64>,\r\n    pub lock_votes: Vec<AggregatedVote<P>>,\r\n    pub proposer: Address,\r\n}\r\n```\r\n\r\n## Vote\r\n\r\n```rust\r\npub struct SignedVote {\r\n    pub signature: Signature,\r\n    pub vote: Vote,\r\n}\r\n\r\npub struct AggregatedVote {\r\n    pub signature: AggregatedSignature,\r\n    pub type: VoteType,\r\n    pub epoch: u64,\r\n    pub round: u64,\r\n    pub proposal: Hash,\r\n}\r\n\r\npub struct Vote {\r\n    pub type: VoteType,\r\n    pub epoch: u64,\r\n    pub round: u64,\r\n    pub proposal: Hash,\r\n    pub voter: Address,\r\n}\r\n```\r\n\r\n## Commit\r\n\r\n```rust\r\npub struct Commit<T> {\r\n    pub epoch: u64,\r\n    pub proposal: T,\r\n    pub proof: Proof,\r\n}\r\n```\r\n\r\n## AggregatedSignature\r\n\r\n```rust\r\npub struct AggregatedSignature {\r\n    pub signature: Signature,\r\n    pub address_bitmap: Vec<u8>,\r\n}\r\n```\r\n\r\n## Proof\r\n\r\n```rust\r\npub struct Proof {\r\n    pub epoch: u64,\r\n    pub round: u64,\r\n    pub proposal_hash: Hash,\r\n    pub signature: AggregatedSignature,\r\n}\r\n```\r\n\r\n## Node\r\n\r\n```rust\r\npub struct Node {\r\n    pub address: Address,\r\n    pub proposal_weight: usize,\r\n    pub vote_weight: usize,\r\n}\r\n```\r\n\r\n## Status\r\n\r\n```rust\r\npub Status {\r\n    pub epoch: u64,\r\n    pub interval: u64,\r\n    pub authority_list: Vec<Node>,\r\n}\r\n```\r\n\r\n## VerifyResp\r\n\r\n```rust\r\npub(crate) struct VerifyResp {\r\n    pub(crate) proposal_hash: Hash,\r\n    pub(crate) is_pass: bool,\r\n}\r\n```\r\n\r\n## Feed\r\n\r\n```rust\r\npub(crate) struct Feed<T> {\r\n    pub(crate) epoch: u64,\r\n    pub(crate) proposal: T,\r\n    pub(crate) hash: Hash,\r\n}\r\n```\r\n","\\zh\\overview.md":"# 概览\r\n\r\n- [概览](#%e6%a6%82%e8%a7%88)\r\n  - [介绍](#%e4%bb%8b%e7%bb%8d)\r\n  - [什么是区块链框架](#%e4%bb%80%e4%b9%88%e6%98%af%e5%8c%ba%e5%9d%97%e9%93%be%e6%a1%86%e6%9e%b6)\r\n  - [Muta 的特点](#muta-%e7%9a%84%e7%89%b9%e7%82%b9)\r\n    - [高性能](#%e9%ab%98%e6%80%a7%e8%83%bd)\r\n    - [高吞吐量的共识算法](#%e9%ab%98%e5%90%9e%e5%90%90%e9%87%8f%e7%9a%84%e5%85%b1%e8%af%86%e7%ae%97%e6%b3%95)\r\n    - [CKB-VM 上的 Account 编程模型](#ckb-vm-%e4%b8%8a%e7%9a%84-account-%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%9e%8b)\r\n    - [First-class Asset](#first-class-asset)\r\n\r\n## 介绍\r\n\r\nMuta 是一个由 Rust 编写的具备可扩展性的高性能区块链框架。它允许你使用 Rust 或 Typescript 编写你的业务逻辑，构建你的专有区块链。\r\n\r\n同时，Muta 还是 Nervos layer2 解决方案 Axon 的底层基础设施，Muta 将内置一套跨链方案联通整个 Nervos 网络。\r\n\r\n## 什么是区块链框架\r\n\r\n有过互联网开发经验的或多或少都会使用一些 Web 框架（eg. Express， Ruby on Rails），这些框架融合了 HTTP 协议解析、URL 解析、请求路由、中间件等必要功能，使用者只需要专注于每个 API 对应的业务逻辑即可。\r\n\r\n区块链框架也一样，在区块链中 **智能合约+链上治理** 即为区块链中的业务逻辑，框架在底层提供了区块链运行的必要模块（eg. 共识算法、虚拟机、P2P）并且提供了稳定性、高性能的保证。\r\n\r\n## Muta 的特点\r\n\r\n### 高性能\r\n\r\nMuta 的目标是达到每秒处理数千个事务（TPS）。在目前的 benchmark 环境中，Muta 的每秒处理事务（TPS）数大约在 2000 左右，出块间隔在 2.5s。\r\n\r\n### 高吞吐量的共识算法\r\n\r\n[Overlord][overlord] 是由 Nervos 研究团队设计研发的 BFT 类共识算法，其设计目标是成为能够支持上百个共识节点，满足数千笔每秒的交易处理能力，且交易延迟不超过数秒。Overlord 的核心思想是解耦交易定序与状态共识，从而实现共识和执行完全并行，极大提高整条链的交易吞吐量。\r\n\r\n### CKB-VM 上的 Account 编程模型\r\n\r\n[CKB-VM][ckb-vm] 是一个实现了 RISCV 指令集的区块链虚拟机，具有高性能，可扩展性，灵活性等优点。\r\n\r\n在 Muta 中，智能合约的编程模型采用的是 Account 模型，相比 UTXO，Account 模型更便于开发复杂逻辑的智能合约。 Account 模型最早是由以太坊所采用的一种智能合约编程模型，并且许多关于操作 Account 的指令都内嵌到了以太坊虚拟机 EVM 中，\r\n\r\n得益于 [CKB-VM][ckb-vm] 的灵活性和可扩展性，在不侵入指令集修改的前提下，我们在 [CKB-VM][ckb-vm] 之上实现了一套 Account SDK 以实现 Muta 中的 Account 模型， 不仅如此，我们还提供了合约编程语言 [Minits][minits]， [Minits][minits] 是一个专为区块链智能合约开发设计的 Typescript 的子集，它使用 LLVM 最终把代码编译成 RISCV 在 [CKB-VM][ckb-vm] 中运行。\r\n\r\n### First-class Asset\r\n\r\n在以太坊等智能合约平台中，用户自定义代币（User Defined Token, UDT）通常以标准智能合约形式出现。平台对某合约记录的是资产还是普通数据没有区分。这样带来了安全性、通用性和复杂性等多重风险。\r\n\r\nLibra 使用的 Move 以及 Nervos CKB 提出了区块链中一等公民（first-class citizen）的概念。在这个概念中资产，或者所属权成为了系统可直接识别的数据，而不是和其他数据糅合在一起对系统保持透明。\r\n\r\nMuta 对原生代币和 UDT 设置了一等公民的地位，我们称之为 first-class asset（简称 FCA）。所有代币的基础行为均由系统提供的原生合约实现，用户只需要给出代币的名称、发行量、管理方式等定义即可创建一等资产。\r\n\r\n这样做的优势除了在于大幅降低实现复杂度、统一资产标准、提高安全性之外，更重要的是系统对代币行为可感知，从而便于实现更底层的经济激励、手续费计算逻辑以及原生跨链等业务。\r\n\r\n[关于 First-class Asset 的更多讨论][first-class asset]\r\n\r\n[overlord]: https://github.com/cryptape/overlord\r\n[ckb-vm]: https://github.com/nervosnetwork/ckb-vm\r\n[minits]: https://github.com/cryptape/minits\r\n[first-class asset]: https://talk.nervos.org/t/first-class-asset/405\r\n","\\zh\\toolchain_minits_on_ckbvm.md":"# 在 CKB-VM 上运行 TypeScript\r\n\r\n- [在 CKB-VM 上运行 TypeScript](#在-ckb-vm-上运行-typescript)\r\n  - [太长不看](#太长不看)\r\n    - [构建 ckb-vm](#构建-ckb-vm)\r\n    - [构建 minits](#构建-minits)\r\n    - [构建 LLVM](#构建-llvm)\r\n    - [构建 riscv-gnu-toolchain](#构建-riscv-gnu-toolchain)\r\n    - [测试代码](#测试代码)\r\n  - [LLVM RISC-V 后端支持情况](#llvm-risc-v-后端支持情况)\r\n  - [坑](#坑)\r\n    - [**Bug 24389** **- can't link soft-float modules with double-float modules**](#bug-24389---cant-link-soft-float-modules-with-double-float-modules)\r\n    - [构建失败](#构建失败)\r\n  - [一些有用的链接](#一些有用的链接)\r\n\r\n[CKB-VM](https://github.com/nervosnetwork/ckb-vm) 是一个能够运行 RISC-V 指令集的虚拟机。要是它支持 TypeScript ，我们可以将 TypeScript 编译到 RISC-V 指令集。这里我们可以借助 [minits](https://github.com/cryptape/minits) 与 [LLVM](https://llvm.org/) 来实现，也就是`TypeScript -- minits --> LLVM IR -- LLVM-RISCV --> RISC-V` 这样一条编译路径最终获得 RISC-V 指令集。\r\n\r\n## 太长不看\r\n\r\n### 构建 ckb-vm\r\n\r\n```shell\r\n git clone https://github.com/nervosnetwork/ckb-vm\r\n cd ckb-vm\r\n cargo build\r\n```\r\n\r\n### 构建 minits\r\n\r\n```shell\r\ngit clone https://github.com/cryptape/minits\r\ncd minits\r\nnpm install \r\nnpm config set cmake_LLVM_DIR $(path-to-llvm/bin/llvm-config --cmakedir)\r\nnpm run build\r\n```\r\n\r\n### 构建 LLVM\r\n\r\n```shell\r\ngit clone https://github.com/llvm/llvm-project.git\r\ncd llvm-project\r\nmkdir build\r\ncd build\r\ncmake -DLLVM_TARGETS_TO_BUILD=\"X86;RISCV;PowerPC\" -DLLVM_ENABLE_PROJECTS=clang -G \"Unix Makefiles\" ../llvm\r\ncmake --build .\r\n```\r\n\r\n### 构建 riscv-gnu-toolchain\r\n\r\n```shell\r\ngit clone --recursive https://github.com/riscv/riscv-gnu-toolchain\r\nsudo apt-get install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev\r\n./configure --prefix=/opt/riscv\r\nmake\r\n```\r\n\r\n### 测试代码\r\n\r\n```typescript\r\n// fib.ts\r\nfunction fibo(n: number): number {\r\n    if (n < 2) {\r\n        return n;\r\n    }\r\n    return fibo(n - 1) + fibo(n - 2);\r\n}\r\n\r\nfunction main(argc: number, argv: string[]): number {\r\n    return fibo(13);\r\n}\r\n```\r\n\r\n```rust\r\n// demo.rs\r\nuse bytes::Bytes;\r\nuse std::io::Read;\r\n\r\nfn main() {\r\n    let args: Vec<Bytes> = std::env::args().map(|a| a.into()).collect();\r\n\r\n    let mut file = std::fs::File::open(\"examples/main\").unwrap();\r\n    let mut buffer = Vec::new();\r\n    file.read_to_end(&mut buffer).unwrap();\r\n    let buffer = Bytes::from(buffer);\r\n\r\n    let r = ckb_vm::run::<u64, ckb_vm::SparseMemory<u64>>(&buffer, &args[..]).unwrap();\r\n    println!(\"result is {:?}\", r);\r\n}\r\n```\r\n\r\n```shell\r\n# minits\r\nnode ./build/main/index.js build main.ts -o main.ll\r\nclang -O -c --target=riscv64 main.ll\r\nrriscv64-unknown-elf-gcc -o main main.o\r\n\r\n# copy main to ckb-vm/examples\r\ncargo run --example demo \r\n```\r\n\r\n## LLVM RISC-V 后端支持情况\r\n\r\n目前 *LLVM 8.x*  RISC-V 后端还处于实验状态，但已经出现在 [Target列表](https://llvm.org/svn/llvm-project/llvm/trunk/lib/Target/RISCV/) 中。[在 *LLVM 9.0* 中 *RISC-V* 支持将有望从实验性功能变更为官方功能](https://lists.llvm.org/pipermail/llvm-dev/2019-July/133724.html)，并已经加入 [RC 版本的 Release Note](http://prereleases.llvm.org/9.0.0/rc6/docs/ReleaseNotes.html#changes-to-the-riscv-target) 。[要开启实验性的功能只能从源码构建](https://stackoverflow.com/questions/46905464/how-to-enable-a-llvm-backend)，目前需要构建需要加上 `-DLLVM_TARGETS_TO_BUILD=\"RISCV\"`参数才能构建出有RISC-V的backend。\r\n\r\n\r\n\r\n## 坑\r\n\r\n### [**Bug 24389**](https://sourceware.org/bugzilla/show_bug.cgi?id=24389) **- can't link soft-float modules with double-float modules**\r\n\r\n在 Mac 上直接使用 brew 安装的版本可能还未修复这个bug，只能在 **Ubuntu 18** 下从源码构建\r\n\r\n### 构建失败\r\n\r\n```\r\ncmake -DLLVM_TARGETS_TO_BUILD=\"RISCV\" -DLLVM_ENABLE_PROJECTS=clang -G \"Unix\r\n Makefiles\" ../llvm\r\n\r\ncollect2: fatal error: ld terminated with signal 9 [Killed]\r\ncompilation terminated.\r\ntools/lto/CMakeFiles/LTO.dir/build.make:167: recipe for target 'lib/libLTO.so.10svn' failed\r\nmake[2]: *** [lib/libLTO.so.10svn] Error 1\r\nmake[2]: *** Deleting file 'lib/libLTO.so.10svn'\r\nCMakeFiles/Makefile2:10139: recipe for target 'tools/lto/CMakeFiles/LTO.dir/all' failed\r\nmake[1]: *** [tools/lto/CMakeFiles/LTO.dir/all] Error 2\r\nMakefile:151: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n```\r\n\r\n## 一些有用的链接\r\n\r\n- [LLVM Target Triple](https://llvm.org/doxygen/classllvm_1_1Triple.html)\r\n- [使用Clang 交叉编译](https://clang.llvm.org/docs/CrossCompilation.html)","\\zh\\transaction_pool.md":"# Mempool\r\n\r\n- [Mempool](#mempool)\r\n  - [设计要求](#%e8%ae%be%e8%ae%a1%e8%a6%81%e6%b1%82)\r\n  - [解决方案](#%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88)\r\n    - [要求1](#%e8%a6%81%e6%b1%821)\r\n    - [要求2](#%e8%a6%81%e6%b1%822)\r\n    - [要求3](#%e8%a6%81%e6%b1%823)\r\n  - [具体设计](#%e5%85%b7%e4%bd%93%e8%ae%be%e8%ae%a1)\r\n\r\n## 设计要求\r\n\r\nMempool 是节点负责收集新交易以及打包新交易给共识模块进行共识的功能模块。很自然地，我们对 Mempool 会提出一些要求：\r\n\r\n1. 性能优秀，在普通计算设备中运行即可达到每秒插入 10000+ 笔交易的性能要求。\r\n2. 公平性，按照收到交易的顺序打包交易。\r\n\r\n此外，为了配合共识过程与交易同步过程并发的设计，还有第三个要求：\r\n\r\n3. 打包给共识的交易包含两部分：用于共识的 order 交易以及用于同步的 propose 交易。\r\n\r\n## 解决方案\r\n\r\n### 要求1\r\n\r\n要获得优秀的性能，首先要分析交易插入的过程，找到性能瓶颈之处对症解决。一笔交易插入 Mempool 的过程包括：\r\n1. 检查交易池是否已满，以避免内存溢出。\r\n2. 检查交易是否已经被交易池包含，以避免重复插入。\r\n3. 检查交易的签名是否正确，格式是否合规，以避免插入明显错误的交易。\r\n4. 检查交易是否已经上链，以避免共识已上链的交易。\r\n\r\n步骤 1, 2 的检查非常快，不是性能瓶颈。\r\n\r\n步骤 3 涉及验签，是耗时操作，好在验签是一个独立的计算密集型操作，很适合用高并发来充分挖掘 CPU 性能，以达到提高性能的要求。\r\n\r\n随着区块链的不断增长，历史交易数据日益庞大，步骤 4 的查询将会成为性能黑洞。我们通过在交易中设置一个必填的 timeout 字段，以及一个全局约束参数 g 来解决该问题。\r\n\r\n具体来说，当某笔交易的 timeout 为 t，若该交易在高度 t 仍未被打包，则会被视为失效而被节点抛弃。为了避免用户设置过高的 timeout，若最新高度为 h 的节点收到的交易的 timeout t > h + g，同样会被节点视为非法而抛弃。在这种机制的约束下，最新高度为 h 的节点仅需保存高度区间为 [h - g, h] 的历史交易用于查重，查重的计算复杂度和存储复杂度均降到了O(g)，与历史交易总量无关。\r\n\r\n### 要求2\r\n\r\n在交易优先级相同的情况下，如果节点后收到的交易却先被打包，这显然有违公平性。因此，交易池的交易必须按照先入先出的原则进行打包。\r\n\r\n然而，如果按照以太坊的 nonce 单调递增的设计（交易中的 nonce 字段的设计是为了确保交易的唯一性），若交易池同时包含多笔同一用户发出的交易，则这些交易之间还需要满足偏序关系，这会给打包机制带来非常大的复杂性。因此，我们采用随机 nonce 的方式生成唯一交易，这种设计还会带来其他一些额外的好处，比如获得了更好的并发执行能力（例如同一个用户发出的多笔交易被同一个区块打包，在以太坊中这些交易必须顺序执行，而采用随机 nonce 后，我们就可以并发执行这些交易），简化钱包的设计（在以太坊中，钱包需要同步最新的 nonce，以避免发出重复的交易，而在我们的设计中就没有这样的要求）。\r\n\r\n总之，强制要求一个用户的所有交易保持偏序是没有必要且低效的，如果某些交易之间存在某种依赖关系，我们可以使用 ref 字段来表示这种关系，以此获得比以太坊更通用的依赖表达，比如用于表示不同用户之间交易的依赖关系。并且我们的顺序打包方案可以很容易地扩展到满足这种依赖需求。\r\n\r\n### 要求3\r\n\r\n由于区块链是一个分布式系统，不同节点的交易池所包含的交易集合不会完全相同。共识过程与交易同步打包的核心思想是，在交易池中包含的交易很多，无法被一次共识完成的情况下（受限于 cycle_limit，类似以太坊的 gas_limit），未参与共识的交易的同步过程可以与共识过程并发进行。通过这样的设计，在下一个高度的共识开始的时候，参与共识的交易的同步过程已经提前一个高度开始了，共识效率因此得到了提升。\r\n\r\n具体来说，就是交易池打包的时候，在 order 交易满了之后，继续打包交易作为 propose 交易。在共识的时候，leader 节点发出的提案中包含了 order 交易 和 propose 交易（提案中包含的实际上都是交易哈希，在共识过程中，我们采用的是 compact block 的设计）。order 交易参与共识，而 propose 交易开始同步。\r\n\r\n注：compact block 设计，leader 发送的 proposal 中仅包含交易哈希，收到 proposal 的节点检查交易哈希是否在本地 Mempool 中，如果没有则向 leader 请求缺失的完整交易。通过 compact block 的设计，可以减少交易传输量，提高带宽利用率。\r\n\r\n## 具体设计\r\n\r\n根据以上分析，我们需要的是一个可以支持高并发插入交易，遵循先入先出原则打包交易，打包有不同用途的两类交易的 Mempool。\r\n\r\n为了满足以上要求，我们用 Map 和 Queue 结构共享存储交易数据，Map 可快速查询和删除，而 Queue 满足先入先出的打包要求。事实上，我们用了两个 queue，就像两个杯子交替倒牛奶。Mempool 的核心数据结构如下：\r\n\r\n```rust\r\nstruct TxCache {\r\n    /// 用 queue 实现先入先出的打包功能. \r\n    /// 用两个 queue 轮流存储交易. 一个 queue 当前轮值, 另一个则作为替补. \r\n    /// 打包时从当前轮值的 queue 中顺序打包.\r\n    queue_0: Queue<SharedTx>,\r\n    queue_1: Queue<SharedTx>,\r\n    /// 用 map 完成高效的随机查询和删除交易.\r\n    map: Map<Hash, SharedTx>,\r\n    /// 指示当前轮值的 queue, true 为 queue_0, false 为 queue_1.\r\n    is_zero: AtomicBool,\r\n    /// 用于原子操作，以妥善处理打包与插入的并发问题. \r\n    concurrent_count: AtomicUsize,\r\n}\r\n\r\n/// 用于 map 和 queue 中共享的交易结构\r\ntype SharedTx = Arc<TxWrapper>;\r\n\r\nstruct TxWrapper {\r\n    tx: SignedTransaction,\r\n    /// 该交易是否被 map 删除，有该标识的交易在打包交易时会被跳过，并且从 queue 中删除\r\n    removed: AtomicBool,\r\n    /// 避免重复同步的标识，有该标识的交易在打包 propose 交易时会被跳过\r\n    proposed: AtomicBool,\r\n}\r\n\r\n/// 用于存储共识同步返回的交易\r\ntype CallbackCache = Map<Hash, SignedTransaction>;\r\n\r\n/// Mempool 打包返回给共识模块的数据结构\r\nstruct MixedTxHashes {\r\n    order_tx_hashes: Vec<Hash>,\r\n    propose_tx_hashes: Vec<Hash>,\r\n}\r\n``` \r\n\r\n通过所有检查的新交易在插入 Mempool 时，首先包装为 `TxWrapper`（`removed` 和 `proposed` 均设置为 `false`）。然后转换为 `SharedTx` 并插入 `TxCache` 中（插入当前轮值的 `queue` 的尾部，以及 `map` 中）。 \r\n\r\nMempool 收到共识的打包请求时，返回 `MixedTxHashes`，其中包含用于共识的 `order_tx_hashes` 和用于提前同步的 `propose_tx_hashes`。\r\n\r\n打包算法如下，从当前轮值的 `queue` 的头部开始弹出交易，跳过 `removed = true` 的 `TxWrapper`，直到达到 `cycle_limit `上限为止，将这些交易哈希插入 `order_tx_hashes` 中。继续弹出交易，跳过 `proposed = true` 的 `TxWrapper`，直到达到 `cycle_limit` 上限为止，将这些交易哈希插入 `propose_tx_hashes` 中。以上弹出的交易除了 `removed = true` 的交易外都按照弹出顺序插入到当前替补的 `queue` 中。当轮值 `queue` 全部弹出后，交换两个 `queue` 的身份。\r\n\r\n当节点收到来自 leader 的 proposal 时，会请求 Mempool 检查 `order_tx_hashes` 和 `propose_tx_hashes`。Mempool 通过查询 `TxCache.map` 确定交易是否存在，对于缺失的交易发起同步请求。对于同步返回的 order 交易插入到 `CallbackCache` 中，而对于同步返回的 propose 交易则插入到 `TxCache`  中，并将 `proposed` 设置为 `true`。\r\n\r\nMempool 收到共识的删除指定 `tx_hashes` 集合的请求时，先清空 `CallbackCache`，然后查询 `TxCache.map`，将对应的 `TxWrapper` 中的 `removed` 设置为 `true`，然后删除该 `SharedTx`。\r\n\r\nMempool 的插入和打包过程如下图所示。\r\n\r\n![image](./resources/mempool_process.png)\r\n","\\zh\\vm_lang.md":"# 合约编程\r\n\r\n由于合约虚拟机使用了 RISCV 指令集, 因此任何可以编译到 RISCV 的编程语言都可以作为合约的编程语言. 虚拟机使用的是 rv64imc 架构, 它基于 RV64I ISA 核心, 具有 M 标准扩展用于整数乘法和除法, 以及 C 标准扩展用于 RCV(RISC-V压缩指令). 注意的是, 虚拟机不支持浮点指令.\r\n\r\n合约开发者可以根据自己的爱好来选择合约开发语言, 或者使用我们专门为 RISCV 虚拟机编写的编程语言: minits. minits 是一个以 LLVM 为后端的 TypeScript 静态编译器, 它可以将 TypeScript 代码编译为 RISCV 指令, 它拥有 TypeScript 的对开发者友好的语法, 同时拥有不亚于 C 语言的执行性能. 可访问 [https://github.com/cryptape/minits](https://github.com/cryptape/minits) 来获取关于 minits 更多的信息.\r\n\r\n# Minits 最小运行模型\r\n\r\n任何合约都已一个 main 函数作为其入口函数, 同时返回一个退出码. 如果退出码非 0, 则意味着合约调用失败.\r\n\r\n```ts\r\nfunction main(argc: number, argv: string[]): number {\r\n    return 0\r\n}\r\n```\r\n\r\n# Example\r\n\r\n下面的代码是一个 SimpleStorage 合约的例子. 该合约允许使用者存储或读取一对 K/V 值. 我们未来会将 syscall, set_storage, get_storage 这些函数以一个 SDK 形式对外提供, 但目前直接写在合约代码中更有利于开发者理解. syscall 是一个特殊的函数, 它允许合约与链上数据进行交互, 比如查询当前链高度, 获取某个账号的余额等.\r\n\r\n```ts\r\n// A simplestorage contract for blockchain.\r\n\r\nconst STORAGE_SET = 2180;\r\nconst STORAGE_GET = 2181;\r\nconst RET = 2182;\r\n\r\nfunction syscall(n: number, a: any, b: any, c: any, d: any, e: any, f: any): number {\r\n    return 0;\r\n}\r\n\r\nfunction set_storage(k: string, v: string): number {\r\n    return syscall(STORAGE_SET, k, v, 0, 0, 0, 0);\r\n}\r\n\r\nfunction get_storage(k: string): string {\r\n    let v = \"\";\r\n    syscall(STORAGE_GET, k, v, 0, 0, 0, 0);\r\n    return v\r\n}\r\n\r\nfunction ret(d: string): number {\r\n    return syscall(RET, d, 0, 0, 0, 0, 0);\r\n}\r\n\r\nfunction main(argc: number, argv: string[]): number {\r\n    if (argc == 1) {\r\n        return 1;\r\n    }\r\n    switch (argv[1]) {\r\n        case \"get\":\r\n            const v = get_storage(argv[2]);\r\n            ret(v);\r\n            return 0;\r\n        case \"set\":\r\n            set_storage(argv[2], argv[3]);\r\n            return 0;\r\n        default:\r\n            return 1;\r\n    }\r\n}\r\n```"}}